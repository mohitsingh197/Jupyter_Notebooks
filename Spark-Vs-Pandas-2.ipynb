{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "import pandas as pd\nimport numpy as np", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 1
        }, 
        {
            "source": "# Reading files in Spark", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\nimport ibmos2spark\n\n# @hidden_cell\ncredentials = {\n    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'api_key': 'pGtcK4Cfe0bYhkzj57xpd52SoW35u9AminIgvd2fgQxN',\n    'service_id': 'iam-ServiceId-8270013a-9afb-4c42-9b56-f62850a9c0f4',\n    'iam_service_endpoint': 'https://iam.ng.bluemix.net/oidc/token'}\n\nconfiguration_name = 'os_9fa254825cf748af8c99d9684609cb33_configs'\ncos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n# Please read the documentation of PySpark to learn more about the possibilities to load data files.\n# PySpark documentation: https://spark.apache.org/docs/2.0.1/api/python/pyspark.sql.html#pyspark.sql.SparkSession\n# The SparkSession object is already initialized for you.\n# The following variable contains the path to your file on your IBM Cloud Object Storage.\nmovies_path = cos.url('movielens_movies.dat', 'sparkscalapythonplayground-donotdelete-pr-pmmafeibz2hwiv')\nratings_path = cos.url('movielens_ratings.dat', 'sparkscalapythonplayground-donotdelete-pr-pmmafeibz2hwiv')\nusers_path = cos.url('movielens_users.dat', 'sparkscalapythonplayground-donotdelete-pr-pmmafeibz2hwiv')\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 17
        }, 
        {
            "source": "# Read movies file", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "movies_df = spark.read.options(delimiter=':').csv(movies_path)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 11
        }, 
        {
            "source": "movies_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(_c0='1', _c1=None, _c2='Toy Story (1995)', _c3=None, _c4=\"Animation|Children's|Comedy\")]"
                    }, 
                    "execution_count": 12, 
                    "metadata": {}
                }
            ], 
            "execution_count": 12
        }, 
        {
            "source": "movies_df = movies_df.drop('_c1', '_c3')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 15
        }, 
        {
            "source": "movies_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(_c0='1', _c2='Toy Story (1995)', _c4=\"Animation|Children's|Comedy\")]"
                    }, 
                    "execution_count": 16, 
                    "metadata": {}
                }
            ], 
            "execution_count": 16
        }, 
        {
            "source": "movies_df = movies_df.withColumn('MovieId', movies_df._c0).withColumn('Title', movies_df._c2).withColumn('Genre', movies_df._c4)\nmovies_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(_c0='1', _c2='Toy Story (1995)', _c4=\"Animation|Children's|Comedy\", MovieId='1', Title='Toy Story (1995)', Genre=\"Animation|Children's|Comedy\")]"
                    }, 
                    "execution_count": 35, 
                    "metadata": {}
                }
            ], 
            "execution_count": 35
        }, 
        {
            "source": "movies_df = movies_df.drop('_c0','_c2','_c4')\nmovies_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(MovieId='1', Title='Toy Story (1995)', Genre=\"Animation|Children's|Comedy\")]"
                    }, 
                    "execution_count": 36, 
                    "metadata": {}
                }
            ], 
            "execution_count": 36
        }, 
        {
            "source": "ratings_df = spark.read.options(delimiter=':').csv(ratings_path)\nratings_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(_c0='1', _c1=None, _c2='1193', _c3=None, _c4='5', _c5=None, _c6='978300760')]"
                    }, 
                    "execution_count": 19, 
                    "metadata": {}
                }
            ], 
            "execution_count": 19
        }, 
        {
            "source": "ratings_df = ratings_df.drop('_c1','_c3','_c5')\nratings_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(_c0='1', _c2='1193', _c4='5', _c6='978300760')]"
                    }, 
                    "execution_count": 20, 
                    "metadata": {}
                }
            ], 
            "execution_count": 20
        }, 
        {
            "source": "ratings_df = ratings_df.withColumn('UserID', ratings_df._c0).withColumn('MoviesId', ratings_df._c2).withColumn('Rating', ratings_df._c4).withColumn('Timestamp', ratings_df._c6)\nratings_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(_c0='1', _c2='1193', _c4='5', _c6='978300760', UserID_='1', MoviesId='1193', Rating='5', Timestamp='978300760', UserID='1')]"
                    }, 
                    "execution_count": 25, 
                    "metadata": {}
                }
            ], 
            "execution_count": 25
        }, 
        {
            "source": "ratings_df = ratings_df.drop('_c0','_c2','_c4','_c6','UserID_')\nratings_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(MoviesId='1193', Rating='5', Timestamp='978300760', UserID='1')]"
                    }, 
                    "execution_count": 27, 
                    "metadata": {}
                }
            ], 
            "execution_count": 27
        }, 
        {
            "source": "users_df = spark.read.options(delimiter=':').csv(users_path)\nusers_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(_c0='1', _c1=None, _c2='F', _c3=None, _c4='1', _c5=None, _c6='10', _c7=None, _c8='48067')]"
                    }, 
                    "execution_count": 30, 
                    "metadata": {}
                }
            ], 
            "execution_count": 30
        }, 
        {
            "source": "users_df = users_df.drop('_c1','_c3','_c5','_c7')\nusers_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(_c0='1', _c2='F', _c4='1', _c6='10', _c8='48067')]"
                    }, 
                    "execution_count": 31, 
                    "metadata": {}
                }
            ], 
            "execution_count": 31
        }, 
        {
            "source": "users_df = users_df.withColumn('UserId', users_df._c0).withColumn('Gender', users_df._c2).withColumn('Age', users_df._c4).withColumn('Occupation', users_df._c6).withColumn('ZipCode', users_df._c8)\nusers_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(_c0='1', _c2='F', _c4='1', _c6='10', _c8='48067', UserId='1', Gender='F', Age='1', Occupation='10', ZipCode='48067')]"
                    }, 
                    "execution_count": 32, 
                    "metadata": {}
                }
            ], 
            "execution_count": 32
        }, 
        {
            "source": "users_df = users_df.drop('_c0','_c2','_c4','_c6','_c8')\nusers_df.take(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[Row(UserId='1', Gender='F', Age='1', Occupation='10', ZipCode='48067')]"
                    }, 
                    "execution_count": 34, 
                    "metadata": {}
                }
            ], 
            "execution_count": 34
        }, 
        {
            "source": "age_dict = {\"1\":  \"Under 18\",'18':  \"18-24\",'25':  \"25-34\",'35':  \"35-44\",'45':  \"45-49\",'50':  \"50-55\", '56':  \"56+\"}\nage_dict", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "{'1': 'Under 18',\n '18': '18-24',\n '25': '25-34',\n '35': '35-44',\n '45': '45-49',\n '50': '50-55',\n '56': '56+'}"
                    }, 
                    "execution_count": 37, 
                    "metadata": {}
                }
            ], 
            "execution_count": 37
        }, 
        {
            "source": "occ_dict = {'0':  \"other or not specified\", '1':  \"academic/educator\", '2':  \"artist\",'3':  \"clerical/admin\",'4':  \"college/grad student\",\\\n            '5':  \"customer service\",'6':  \"doctor/health care\",'7':  \"executive/managerial\",'8':  \"farmer\",'9':  \"homemaker\",\\\n            '10':  \"K-12 student\",'11':  \"lawyer\",'12':  \"programmer\",'13':  \"retired\",'14':  \"sales/marketing\",'15':  \"scientist\",\\\n            '16':  \"self-employed\",'17':  \"technician/engineer\",'18':  \"tradesman/craftsman\",'19':  \"unemployed\",'20':  \"writer\"}\nocc_dict", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "{'0': 'other or not specified',\n '1': 'academic/educator',\n '10': 'K-12 student',\n '11': 'lawyer',\n '12': 'programmer',\n '13': 'retired',\n '14': 'sales/marketing',\n '15': 'scientist',\n '16': 'self-employed',\n '17': 'technician/engineer',\n '18': 'tradesman/craftsman',\n '19': 'unemployed',\n '2': 'artist',\n '20': 'writer',\n '3': 'clerical/admin',\n '4': 'college/grad student',\n '5': 'customer service',\n '6': 'doctor/health care',\n '7': 'executive/managerial',\n '8': 'farmer',\n '9': 'homemaker'}"
                    }, 
                    "execution_count": 38, 
                    "metadata": {}
                }
            ], 
            "execution_count": 38
        }, 
        {
            "source": "print(movies_df.take(1))\nprint(ratings_df.take(1))\nprint(users_df.take(1))\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[Row(MovieId='1', Title='Toy Story (1995)', Genre=\"Animation|Children's|Comedy\")]\n[Row(MoviesId='1193', Rating='5', Timestamp='978300760', UserID='1')]\n[Row(UserId='1', Gender='F', Age='1', Occupation='10', ZipCode='48067')]\n"
                }
            ], 
            "execution_count": 41
        }, 
        {
            "source": "# Which user gave the max number of Rating 1", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from pyspark.sql import functions as F", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 45
        }, 
        {
            "source": "rating_count = ratings_df[ratings_df.Rating == '1'].groupby('UserId').agg(F.count('Rating').alias('Count'))\nmax_count = rating_count.withColumn('tempId', F.lit(0)).groupBy('tempId').agg(F.max('Count').alias('MaxCount')).select('MaxCount').first()[0]\nrating_count.select('UserId', 'Count').where(rating_count.Count == max_count).show()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+------+-----+\n|UserId|Count|\n+------+-----+\n|  4227|  401|\n+------+-----+\n\n"
                }
            ], 
            "execution_count": 53
        }, 
        {
            "source": "# Which movie got the max number of 5 rating", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#[Row(MovieId='1', Title='Toy Story (1995)', Genre=\"Animation|Children's|Comedy\")]\n#[Row(MoviesId='1193', Rating='5', Timestamp='978300760', UserID='1')]\n\nmax_5ratings = ratings_df[ratings_df.Rating == '5'].groupBy(ratings_df.MoviesId).agg(F.count(ratings_df.MoviesId).alias('Max5Ratings'))\nmax_rating_count = max_5ratings.withColumn('tempId', F.lit(0)).groupBy('tempId').agg(F.max('Max5Ratings').alias('Max5Rating')).select('Max5Rating').first()[0]\nmovi_rating_max_5 = max_5ratings.select(max_5ratings.MoviesId, max_5ratings.Max5Ratings).where(max_5ratings.Max5Ratings == max_rating_count)\nmovi_rating_max_5.join(movies_df, movi_rating_max_5.MoviesId == movies_df.MovieId, how='left_outer').select('Title', 'Max5Ratings').show()\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------------------+-----------+\n|               Title|Max5Ratings|\n+--------------------+-----------+\n|American Beauty (...|       1963|\n+--------------------+-----------+\n\n"
                }
            ], 
            "execution_count": 70
        }, 
        {
            "source": "# Reading files in Pandas", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "movies_pdf = pd.read_csv(movies_path)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "File b'cos://sparkscalapythonplayground-donotdelete-pr-pmmafeibz2hwiv.os_9fa254825cf748af8c99d9684609cb33_configs/movielens_movies.dat' does not exist", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-40-cba7c856881b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmovies_pdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n", 
                        "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n", 
                        "\u001b[0;31mFileNotFoundError\u001b[0m: File b'cos://sparkscalapythonplayground-donotdelete-pr-pmmafeibz2hwiv.os_9fa254825cf748af8c99d9684609cb33_configs/movielens_movies.dat' does not exist"
                    ], 
                    "ename": "FileNotFoundError"
                }
            ], 
            "execution_count": 40
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}